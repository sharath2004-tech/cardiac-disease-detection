{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharath2004-tech/cardiac-disease-detection/blob/main/cardiac%20disease%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p2Jeth8dGHR",
        "outputId": "0836c48c-2269-4998-877e-5defed3f1d1c"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (65368997.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install wfdb\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "pip install wfdb\n",
        "\n",
        "\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I73C5-hjdGHS",
        "outputId": "e1eb49c4-2fb4-4968-e353-011eac0df601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating record list for: 100\n",
            "Generating record list for: 101\n",
            "Generating record list for: 102\n",
            "Generating record list for: 103\n",
            "Generating record list for: 104\n",
            "Generating record list for: 105\n",
            "Generating record list for: 106\n",
            "Generating record list for: 107\n",
            "Generating record list for: 108\n",
            "Generating record list for: 109\n",
            "Generating record list for: 111\n",
            "Generating record list for: 112\n",
            "Generating record list for: 113\n",
            "Generating record list for: 114\n",
            "Generating record list for: 115\n",
            "Generating record list for: 116\n",
            "Generating record list for: 117\n",
            "Generating record list for: 118\n",
            "Generating record list for: 119\n",
            "Generating record list for: 121\n",
            "Generating record list for: 122\n",
            "Generating record list for: 123\n",
            "Generating record list for: 124\n",
            "Generating record list for: 200\n",
            "Generating record list for: 201\n",
            "Generating record list for: 202\n",
            "Generating record list for: 203\n",
            "Generating record list for: 205\n",
            "Generating record list for: 207\n",
            "Generating record list for: 208\n",
            "Generating record list for: 209\n",
            "Generating record list for: 210\n",
            "Generating record list for: 212\n",
            "Generating record list for: 213\n",
            "Generating record list for: 214\n",
            "Generating record list for: 215\n",
            "Generating record list for: 217\n",
            "Generating record list for: 219\n",
            "Generating record list for: 220\n",
            "Generating record list for: 221\n",
            "Generating record list for: 222\n",
            "Generating record list for: 223\n",
            "Generating record list for: 228\n",
            "Generating record list for: 230\n",
            "Generating record list for: 231\n",
            "Generating record list for: 232\n",
            "Generating record list for: 233\n",
            "Generating record list for: 234\n",
            "Generating list of all files for: 100\n",
            "Generating list of all files for: 101\n",
            "Generating list of all files for: 102\n",
            "Generating list of all files for: 103\n",
            "Generating list of all files for: 104\n",
            "Generating list of all files for: 105\n",
            "Generating list of all files for: 106\n",
            "Generating list of all files for: 107\n",
            "Generating list of all files for: 108\n",
            "Generating list of all files for: 109\n",
            "Generating list of all files for: 111\n",
            "Generating list of all files for: 112\n",
            "Generating list of all files for: 113\n",
            "Generating list of all files for: 114\n",
            "Generating list of all files for: 115\n",
            "Generating list of all files for: 116\n",
            "Generating list of all files for: 117\n",
            "Generating list of all files for: 118\n",
            "Generating list of all files for: 119\n",
            "Generating list of all files for: 121\n",
            "Generating list of all files for: 122\n",
            "Generating list of all files for: 123\n",
            "Generating list of all files for: 124\n",
            "Generating list of all files for: 200\n",
            "Generating list of all files for: 201\n",
            "Generating list of all files for: 202\n",
            "Generating list of all files for: 203\n",
            "Generating list of all files for: 205\n",
            "Generating list of all files for: 207\n",
            "Generating list of all files for: 208\n",
            "Generating list of all files for: 209\n",
            "Generating list of all files for: 210\n",
            "Generating list of all files for: 212\n",
            "Generating list of all files for: 213\n",
            "Generating list of all files for: 214\n",
            "Generating list of all files for: 215\n",
            "Generating list of all files for: 217\n",
            "Generating list of all files for: 219\n",
            "Generating list of all files for: 220\n",
            "Generating list of all files for: 221\n",
            "Generating list of all files for: 222\n",
            "Generating list of all files for: 223\n",
            "Generating list of all files for: 228\n",
            "Generating list of all files for: 230\n",
            "Generating list of all files for: 231\n",
            "Generating list of all files for: 232\n",
            "Generating list of all files for: 233\n",
            "Generating list of all files for: 234\n",
            "Created local base download directory: mitdb\n",
            "Downloading files...\n",
            "Finished downloading files\n"
          ]
        }
      ],
      "source": [
        "wfdb.dl_database(\n",
        "    'mitdb',\n",
        "    dl_dir='mitdb',\n",
        "    keep_subdirs=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_itPsjMdGHS",
        "outputId": "911543eb-67d8-4704-f450-0e2b47fa3741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Signal shape: (650000,)\n",
            "Total beats: 2274\n"
          ]
        }
      ],
      "source": [
        "import wfdb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "record = wfdb.rdrecord('mitdb/100')\n",
        "annotation = wfdb.rdann('mitdb/100', 'atr')\n",
        "\n",
        "signal = record.p_signal[:,0]   # use first channel\n",
        "r_peaks = annotation.sample\n",
        "labels = annotation.symbol\n",
        "\n",
        "print(\"Signal shape:\", signal.shape)\n",
        "print(\"Total beats:\", len(r_peaks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfJSmA0qdGHT",
        "outputId": "4bb2a85e-2b90-497d-a459-cbe3da72a321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beats shape: (2271, 180)\n"
          ]
        }
      ],
      "source": [
        "beats = []\n",
        "beat_labels = []\n",
        "\n",
        "for i in range(len(r_peaks)):\n",
        "    start = r_peaks[i] - 90\n",
        "    end = r_peaks[i] + 90\n",
        "\n",
        "    if start > 0 and end < len(signal):\n",
        "        beat = signal[start:end]\n",
        "        beats.append(beat)\n",
        "        beat_labels.append(labels[i])\n",
        "\n",
        "beats = np.array(beats)\n",
        "print(\"Beats shape:\", beats.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwSiNcnrdGHT"
      },
      "outputs": [],
      "source": [
        "AAMI_map = {\n",
        "    'N':'N','L':'N','R':'N','e':'N','j':'N',\n",
        "    'A':'S','a':'S','J':'S','S':'S',\n",
        "    'V':'V','E':'V',\n",
        "    'F':'F'\n",
        "}\n",
        "\n",
        "class_to_int = {'N':0,'S':1,'V':2,'F':3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy0TPZhldGHU",
        "outputId": "f777f6e6-831e-44ff-b357-626abc83d8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train records: 22\n",
            "Test records: 22\n",
            "Overlap: set()\n"
          ]
        }
      ],
      "source": [
        "# Standard DS1 (Train) and DS2 (Test) split used in research\n",
        "\n",
        "train_records = [\n",
        "    '101','106','108','109','112','114','115','116',\n",
        "    '118','119','122','124','201','203','205','207',\n",
        "    '208','209','215','220','223','230'\n",
        "]\n",
        "\n",
        "test_records = [\n",
        "    '100','103','105','111','113','117','121','123',\n",
        "    '200','202','210','212','213','214','219','221',\n",
        "    '222','228','231','232','233','234'\n",
        "]\n",
        "\n",
        "print(\"Train records:\", len(train_records))\n",
        "print(\"Test records:\", len(test_records))\n",
        "\n",
        "# Safety check (no leakage)\n",
        "print(\"Overlap:\", set(train_records) & set(test_records))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3CUjCATdGHU"
      },
      "outputs": [],
      "source": [
        "def extract_beats(record_list):\n",
        "    beats = []\n",
        "    labels = []\n",
        "\n",
        "    for rec in record_list:\n",
        "        print(f\"Processing record {rec}...\")\n",
        "\n",
        "        record = wfdb.rdrecord(f'mitdb/{rec}')\n",
        "        annotation = wfdb.rdann(f'mitdb/{rec}', 'atr')\n",
        "\n",
        "        signal = record.p_signal[:, 0]   # Use first channel\n",
        "        r_peaks = annotation.sample\n",
        "        symbols = annotation.symbol\n",
        "\n",
        "        for i in range(len(r_peaks)):\n",
        "            start = r_peaks[i] - 90\n",
        "            end = r_peaks[i] + 90\n",
        "\n",
        "            if start > 0 and end < len(signal):\n",
        "                label = symbols[i]\n",
        "\n",
        "                if label in AAMI_map:\n",
        "                    beat = signal[start:end]\n",
        "\n",
        "                    # Per-beat normalization\n",
        "                    mean = np.mean(beat)\n",
        "                    std = np.std(beat)\n",
        "                    beat = (beat - mean) / (std + 1e-8)\n",
        "\n",
        "                    beats.append(beat)\n",
        "                    labels.append(class_to_int[AAMI_map[label]])\n",
        "\n",
        "    return np.array(beats), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5erwntlRdGHV",
        "outputId": "4f346e47-da3d-4adf-e6c4-6c9eec0a7259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing record 101...\n",
            "Processing record 106...\n",
            "Processing record 108...\n",
            "Processing record 109...\n",
            "Processing record 112...\n",
            "Processing record 114...\n",
            "Processing record 115...\n",
            "Processing record 116...\n",
            "Processing record 118...\n",
            "Processing record 119...\n",
            "Processing record 122...\n",
            "Processing record 124...\n",
            "Processing record 201...\n",
            "Processing record 203...\n",
            "Processing record 205...\n",
            "Processing record 207...\n",
            "Processing record 208...\n",
            "Processing record 209...\n",
            "Processing record 215...\n",
            "Processing record 220...\n",
            "Processing record 223...\n",
            "Processing record 230...\n",
            "Processing record 100...\n",
            "Processing record 103...\n",
            "Processing record 105...\n",
            "Processing record 111...\n",
            "Processing record 113...\n",
            "Processing record 117...\n",
            "Processing record 121...\n",
            "Processing record 123...\n",
            "Processing record 200...\n",
            "Processing record 202...\n",
            "Processing record 210...\n",
            "Processing record 212...\n",
            "Processing record 213...\n",
            "Processing record 214...\n",
            "Processing record 219...\n",
            "Processing record 221...\n",
            "Processing record 222...\n",
            "Processing record 228...\n",
            "Processing record 231...\n",
            "Processing record 232...\n",
            "Processing record 233...\n",
            "Processing record 234...\n",
            "Train shape: (51002, 180)\n",
            "Test shape: (49691, 180)\n",
            "Unique classes in train: [0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = extract_beats(train_records)\n",
        "X_test, y_test = extract_beats(test_records)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "\n",
        "import numpy as np\n",
        "print(\"Unique classes in train:\", np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS3lxlAqdGHV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        beat = self.X[idx].clone()\n",
        "\n",
        "        if self.augment:\n",
        "            # Gaussian noise (stronger, more frequent)\n",
        "            if random.random() > 0.3:\n",
        "                noise = torch.randn_like(beat) * random.uniform(0.01, 0.05)\n",
        "                beat = beat + noise\n",
        "\n",
        "            # Amplitude scaling (wider range)\n",
        "            if random.random() > 0.3:\n",
        "                scale = random.uniform(0.85, 1.15)\n",
        "                beat = beat * scale\n",
        "\n",
        "            # Time shifting (larger shifts)\n",
        "            if random.random() > 0.3:\n",
        "                shift = random.randint(-15, 15)\n",
        "                beat = torch.roll(beat, shift, dims=-1)\n",
        "\n",
        "            # Baseline wander (stronger)\n",
        "            if random.random() > 0.3:\n",
        "                baseline = torch.sin(torch.linspace(0, random.uniform(3, 5)*3.14159, beat.size(-1))) * random.uniform(0.03, 0.08)\n",
        "                beat = beat + baseline.unsqueeze(0)\n",
        "            \n",
        "            # Random smoothing\n",
        "            if random.random() > 0.5:\n",
        "                kernel_size = random.choice([3, 5])\n",
        "                beat = F.avg_pool1d(beat.unsqueeze(0), kernel_size, stride=1, padding=kernel_size//2).squeeze(0)\n",
        "\n",
        "        return beat, self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_HDFWk0dGHV"
      },
      "outputs": [],
      "source": [
        "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
        "test_dataset = ECGDataset(X_test, y_test, augment=False)\n",
        "\n",
        "# Optimized batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzljxzgEdGHW",
        "outputId": "d98b1a16-75ca-4649-b857-4f2b631f7c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0: 45856\n",
            "Class 1: 944\n",
            "Class 2: 3788\n",
            "Class 3: 414\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply SMOTE to balance the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"APPLYING SMOTE OVERSAMPLING\")\n",
        "print(\"=\"*50)\n",
        "print(\"Before SMOTE:\")\n",
        "unique_before, counts_before = np.unique(y_train, return_counts=True)\n",
        "for u, c in zip(unique_before, counts_before):\n",
        "    print(f\"  Class {u}: {c}\")\n",
        "\n",
        "# Apply SMOTE - Increase S and F targets significantly\n",
        "# These classes need MORE synthetic examples\n",
        "smote = SMOTE(sampling_strategy={\n",
        "    1: 30000,  # S: Increased from 20,000 to 30,000\n",
        "    2: 20000,  # V: Keep at 20,000 (performing well)\n",
        "    3: 25000   # F: Increased from 15,000 to 25,000\n",
        "}, random_state=42, k_neighbors=5)\n",
        "\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "unique_after, counts_after = np.unique(y_train_balanced, return_counts=True)\n",
        "for u, c in zip(unique_after, counts_after):\n",
        "    print(f\"  Class {u}: {c}\")\n",
        "print(f\"\\nTotal samples: {len(y_train_balanced):,}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Use balanced data\n",
        "X_train = X_train_balanced\n",
        "y_train = y_train_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtSY8J4VdGHW",
        "outputId": "15ce62a3-026a-486e-bfeb-37f12ab1df7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: tensor([ 0.2781, 13.5069,  3.3660, 30.7983], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Manual class weights - EXTREME boost for S and F\n",
        "# These classes are being completely ignored\n",
        "alpha = torch.tensor([\n",
        "    0.3,   # N: Reduce further (model overpredicts this)\n",
        "    8.0,   # S: MUCH higher weight (was 3.0, now 8.0)\n",
        "    1.0,   # V: Keep moderate (performing well)\n",
        "    15.0   # F: EXTREME weight (was 5.0, now 15.0)\n",
        "], dtype=torch.float32)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alpha = alpha.to(device)\n",
        "\n",
        "print(\"Class weights:\", alpha)\n",
        "\n",
        "print(f\"\\nManual Class Weights: {alpha}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCmK-yrCdGHW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.query = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.key = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.value = nn.Conv1d(channels, channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, length = x.size()\n",
        "\n",
        "        q = self.query(x).view(batch, -1, length).permute(0, 2, 1)\n",
        "        k = self.key(x).view(batch, -1, length)\n",
        "        v = self.value(x).view(batch, -1, length)\n",
        "\n",
        "        attention = torch.bmm(q, k)\n",
        "        attention = F.softmax(attention / math.sqrt(channels // 8), dim=-1)\n",
        "\n",
        "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, channels, length)\n",
        "\n",
        "        return self.gamma * out + x\n",
        "\n",
        "\n",
        "class ECGResNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = ResidualBlock(32, 64, dropout=0.3)\n",
        "        self.layer3 = ResidualBlock(64, 128, dropout=0.4)\n",
        "        self.layer4 = ResidualBlock(128, 256, dropout=0.4)\n",
        "        self.layer5 = ResidualBlock(256, 256, dropout=0.5)\n",
        "\n",
        "        self.attention = SelfAttention(256)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.bn_fc = nn.BatchNorm1d(256)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "\n",
        "        self.fc3 = nn.Linear(128, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "\n",
        "        x = self.attention(x)\n",
        "\n",
        "        # Concatenate avg and max pooling\n",
        "        avg_pool = self.global_pool(x).squeeze(-1)\n",
        "        max_pool = self.global_max_pool(x).squeeze(-1)\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
        "\n",
        "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfBaNsxVdGHX",
        "outputId": "d94a4957-3868-476b-caf0-d135d1416ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Model parameters: 1596869\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ECGResNet().to(device)\n",
        "\n",
        "# Lower learning rate with stronger weight decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-3)\n",
        "\n",
        "# Better scheduler: ReduceLROnPlateau for adaptive learning rate\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='max', factor=0.5, patience=3\n",
        ")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTIONAL: Focal Loss for Extreme Class Imbalance\n",
        "# Uncomment the code below to use Focal Loss instead of Label Smoothing\n",
        "# Focal Loss focuses more on hard-to-classify examples (S and F classes)\n",
        "\n",
        "# class FocalLoss(nn.Module):\n",
        "#     def __init__(self, alpha=None, gamma=2.0):\n",
        "#         super().__init__()\n",
        "#         self.alpha = alpha\n",
        "#         self.gamma = gamma\n",
        "#     \n",
        "#     def forward(self, pred, target):\n",
        "#         ce_loss = F.cross_entropy(pred, target, reduction='none')\n",
        "#         pt = torch.exp(-ce_loss)\n",
        "#         focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "#         \n",
        "#         if self.alpha is not None:\n",
        "#             focal_loss = self.alpha[target] * focal_loss\n",
        "#         \n",
        "#         return focal_loss.mean()\n",
        "# \n",
        "# # Use Focal Loss with strong alpha and gamma=2.0\n",
        "# criterion = FocalLoss(alpha=alpha, gamma=2.0)\n",
        "# print(\"Using Focal Loss with gamma=2.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ ADVANCED MODEL: Hybrid CNN-Transformer\n",
        "\n",
        "This model uses:\n",
        "- **Multi-scale CNN branches** (3, 5, 7 kernel sizes) to capture different temporal patterns\n",
        "- **Transformer layers** for long-range dependencies in ECG signals\n",
        "- **Focal Loss** to automatically focus on hard-to-classify S and F classes\n",
        "- **~2.8M parameters** (vs 1.6M) for better representational capacity\n",
        "\n",
        "**Expected Performance: 90-92% overall + 50-65% S/F recall**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the advanced model\n",
        "from advanced_model import AdvancedECGClassifier, FocalLoss\n",
        "\n",
        "# Create the advanced model\n",
        "model_advanced = AdvancedECGClassifier(num_classes=4).to(device)\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "print(\"Advanced Model parameters:\", sum(p.numel() for p in model_advanced.parameters() if p.requires_grad))\n",
        "print(f\"Capacity increase: {sum(p.numel() for p in model_advanced.parameters() if p.requires_grad) / sum(p.numel() for p in model.parameters() if p.requires_grad):.2f}x larger\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use FOCAL LOSS - better for extreme class imbalance\n",
        "criterion_focal = FocalLoss(alpha=alpha, gamma=2.0)\n",
        "\n",
        "# Optimizer with slightly higher LR for bigger model\n",
        "optimizer_advanced = torch.optim.AdamW(\n",
        "    model_advanced.parameters(), \n",
        "    lr=0.0005,  # Higher LR for Transformer\n",
        "    weight_decay=1e-3,\n",
        "    betas=(0.9, 0.999)\n",
        ")\n",
        "\n",
        "# Cosine Annealing with Warm Restarts - better for convergence\n",
        "scheduler_advanced = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer_advanced, T_0=10, T_mult=2, eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(\"âœ“ Using Focal Loss (gamma=2.0) - focuses on hard examples\")\n",
        "print(\"âœ“ Using CosineAnnealingWarmRestarts - better convergence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modified training function for advanced model with Focal Loss\n",
        "def train_advanced_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    warmup_epochs = 5\n",
        "    base_lr = 0.0005\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        # Warmup learning rate\n",
        "        if epoch < warmup_epochs:\n",
        "            lr = base_lr * (epoch + 1) / warmup_epochs\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            # With Focal Loss, we can use standard training (no special mixup logic needed)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_loss = 0\n",
        "        \n",
        "        # Track per-class accuracy\n",
        "        class_correct = [0, 0, 0, 0]\n",
        "        class_total = [0, 0, 0, 0]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += targets.size(0)\n",
        "                val_correct += (predicted == targets).sum().item()\n",
        "                \n",
        "                # Per-class tracking\n",
        "                for i in range(4):\n",
        "                    mask = targets == i\n",
        "                    if mask.sum() > 0:\n",
        "                        class_total[i] += mask.sum().item()\n",
        "                        class_correct[i] += ((predicted == targets) & mask).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        \n",
        "        # Step scheduler after warmup\n",
        "        if epoch >= warmup_epochs:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "            }, 'best_model_advanced.pth')\n",
        "            print(f\"âœ“ Saved new best model (Val Acc: {val_acc:.2f}%)\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Show per-class performance every 2 epochs\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            class_names = ['N', 'S', 'V', 'F']\n",
        "            class_accs = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(4)]\n",
        "            class_str = \" | \".join([f\"{name}:{acc:.1f}%\" for name, acc in zip(class_names, class_accs)])\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Best: {best_val_acc:.2f}% | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "            print(f\"  Per-class: {class_str}\")\n",
        "        else:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Best: {best_val_acc:.2f}% | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= 7:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Load best model\n",
        "    checkpoint = torch.load('best_model_advanced.pth')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "    return model\n",
        "\n",
        "print(\"âœ“ Advanced training function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the advanced model\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING ADVANCED CNN-TRANSFORMER MODEL\")\n",
        "print(\"=\"*60)\n",
        "model_advanced = train_advanced_model(\n",
        "    model_advanced, train_loader, test_loader, \n",
        "    criterion_focal, optimizer_advanced, scheduler_advanced, \n",
        "    epochs=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the Advanced Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model_advanced.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model_advanced(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ADVANCED MODEL - DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(all_targets, all_preds, \n",
        "                            target_names=['N (Normal)', 'S (Supraventricular)', 'V (Ventricular)', 'F (Fusion)'],\n",
        "                            digits=4))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "plt.figure(figsize=(12, 9))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', \n",
        "            xticklabels=['N', 'S', 'V', 'F'],\n",
        "            yticklabels=['N', 'S', 'V', 'F'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Actual', fontsize=14, fontweight='bold')\n",
        "plt.title('Advanced Model - Confusion Matrix\\nCNN-Transformer with Focal Loss', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Per-class accuracy with color coding\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PER-CLASS PERFORMANCE\")\n",
        "print(\"=\"*70)\n",
        "for i, class_name in enumerate(['N (Normal)', 'S (Supraventricular)', 'V (Ventricular)', 'F (Fusion)']):\n",
        "    class_correct = cm[i, i]\n",
        "    class_total = cm[i].sum()\n",
        "    class_acc = 100 * class_correct / class_total if class_total > 0 else 0\n",
        "    \n",
        "    # Color code based on performance\n",
        "    if class_acc >= 85:\n",
        "        status = \"âœ… EXCELLENT\"\n",
        "    elif class_acc >= 70:\n",
        "        status = \"âœ“ GOOD\"\n",
        "    elif class_acc >= 50:\n",
        "        status = \"âš  FAIR\"\n",
        "    else:\n",
        "        status = \"âŒ POOR\"\n",
        "    \n",
        "    print(f\"{class_name:25s}: {class_acc:6.2f}% ({class_correct:5d}/{class_total:5d}) {status}\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtZR28AYdGHX"
      },
      "outputs": [],
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1, weight=None):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        n_class = pred.size(1)\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, target.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - self.smoothing) + self.smoothing / n_class\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        if self.weight is not None:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1)\n",
        "            loss = (loss * self.weight[target]).mean()\n",
        "        else:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "        return loss\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing=0.1, weight=alpha)\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Apply Mixup augmentation'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    \n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "    \n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    warmup_epochs = 5\n",
        "    base_lr = 0.0005\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        # Warmup learning rate\n",
        "        if epoch < warmup_epochs:\n",
        "            lr = base_lr * (epoch + 1) / warmup_epochs\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            # DISABLE Mixup for minority classes (S=1, F=3)\n",
        "            # Only apply to majority classes to avoid diluting rare patterns\n",
        "            has_minority = torch.any((targets == 1) | (targets == 3))\n",
        "            \n",
        "            if random.random() > 0.7 and not has_minority:\n",
        "                # Apply Mixup only 30% of time, and only for batches without S or F\n",
        "                inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=0.2)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "            else:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += targets.size(0)\n",
        "                val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        \n",
        "        # Step scheduler after warmup\n",
        "        if epoch >= warmup_epochs:\n",
        "            scheduler.step(val_acc)\n",
        "\n",
        "        # Track best model and save checkpoint\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "            }, 'best_model.pth')\n",
        "            print(f\"âœ“ Saved new best model (Val Acc: {val_acc:.2f}%)\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Acc: {train_acc:.2f}% \"\n",
        "              f\"Val Acc: {val_acc:.2f}% \"\n",
        "              f\"Best Val: {best_val_acc:.2f}% \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Early stopping to prevent overfitting\n",
        "        if patience_counter >= 5:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nBest Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Load best model\n",
        "    checkpoint = torch.load('best_model.pth')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "U6OuUlzRdGHX",
        "outputId": "2c13dc18-5edb-4ad9-adb7-7f297fb78645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50] Train Acc: 77.45% Val Acc: 52.73% Best Val: 52.73% LR: 0.000976\n",
            "Epoch [2/50] Train Acc: 90.10% Val Acc: 77.20% Best Val: 77.20% LR: 0.000905\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2686/796181236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2686/2741438827.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             )\n\u001b[0;32m--> 630\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model performance per class\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(all_targets, all_preds, \n",
        "                            target_names=['N (Normal)', 'S (Supraventricular)', 'V (Ventricular)', 'F (Fusion)'],\n",
        "                            digits=4))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['N', 'S', 'V', 'F'],\n",
        "            yticklabels=['N', 'S', 'V', 'F'])\n",
        "plt.xlabel('Predicted', fontsize=12)\n",
        "plt.ylabel('Actual', fontsize=12)\n",
        "plt.title('Confusion Matrix - ECG Cardiac Disease Classification', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Per-class accuracy\n",
        "for i, class_name in enumerate(['N (Normal)', 'S (Supraventricular)', 'V (Ventricular)', 'F (Fusion)']):\n",
        "    class_correct = cm[i, i]\n",
        "    class_total = cm[i].sum()\n",
        "    class_acc = 100 * class_correct / class_total if class_total > 0 else 0\n",
        "    print(f\"{class_name}: {class_acc:.2f}% ({class_correct}/{class_total})\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
