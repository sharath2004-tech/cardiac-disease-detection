{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharath2004-tech/cardiac-disease-detection/blob/main/cardiac%20disease%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install wfdb\n",
        "\n",
        "\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "wfdb.dl_database(\n",
        "    'mitdb',\n",
        "    dl_dir='mitdb',\n",
        "    keep_subdirs=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wfdb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "record = wfdb.rdrecord('mitdb/100')\n",
        "annotation = wfdb.rdann('mitdb/100', 'atr')\n",
        "\n",
        "signal = record.p_signal[:,0]   # use first channel\n",
        "r_peaks = annotation.sample\n",
        "labels = annotation.symbol\n",
        "\n",
        "print(\"Signal shape:\", signal.shape)\n",
        "print(\"Total beats:\", len(r_peaks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "beats = []\n",
        "beat_labels = []\n",
        "\n",
        "for i in range(len(r_peaks)):\n",
        "    start = r_peaks[i] - 90\n",
        "    end = r_peaks[i] + 90\n",
        "\n",
        "    if start > 0 and end < len(signal):\n",
        "        beat = signal[start:end]\n",
        "        beats.append(beat)\n",
        "        beat_labels.append(labels[i])\n",
        "\n",
        "beats = np.array(beats)\n",
        "print(\"Beats shape:\", beats.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AAMI_map = {\n",
        "    'N':'N','L':'N','R':'N','e':'N','j':'N',\n",
        "    'A':'S','a':'S','J':'S','S':'S',\n",
        "    'V':'V','E':'V',\n",
        "    'F':'F'\n",
        "}\n",
        "\n",
        "class_to_int = {'N':0,'S':1,'V':2,'F':3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard DS1 (Train) and DS2 (Test) split used in research\n",
        "\n",
        "train_records = [\n",
        "    '101','106','108','109','112','114','115','116',\n",
        "    '118','119','122','124','201','203','205','207',\n",
        "    '208','209','215','220','223','230'\n",
        "]\n",
        "\n",
        "test_records = [\n",
        "    '100','103','105','111','113','117','121','123',\n",
        "    '200','202','210','212','213','214','219','221',\n",
        "    '222','228','231','232','233','234'\n",
        "]\n",
        "\n",
        "print(\"Train records:\", len(train_records))\n",
        "print(\"Test records:\", len(test_records))\n",
        "\n",
        "# Safety check (no leakage)\n",
        "print(\"Overlap:\", set(train_records) & set(test_records))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_beats(record_list):\n",
        "    beats = []\n",
        "    labels = []\n",
        "\n",
        "    for rec in record_list:\n",
        "        print(f\"Processing record {rec}...\")\n",
        "\n",
        "        record = wfdb.rdrecord(f'mitdb/{rec}')\n",
        "        annotation = wfdb.rdann(f'mitdb/{rec}', 'atr')\n",
        "\n",
        "        signal = record.p_signal[:, 0]   # Use first channel\n",
        "        r_peaks = annotation.sample\n",
        "        symbols = annotation.symbol\n",
        "\n",
        "        for i in range(len(r_peaks)):\n",
        "            start = r_peaks[i] - 90\n",
        "            end = r_peaks[i] + 90\n",
        "\n",
        "            if start > 0 and end < len(signal):\n",
        "                label = symbols[i]\n",
        "\n",
        "                if label in AAMI_map:\n",
        "                    beat = signal[start:end]\n",
        "\n",
        "                    # Per-beat normalization\n",
        "                    mean = np.mean(beat)\n",
        "                    std = np.std(beat)\n",
        "                    beat = (beat - mean) / (std + 1e-8)\n",
        "\n",
        "                    beats.append(beat)\n",
        "                    labels.append(class_to_int[AAMI_map[label]])\n",
        "\n",
        "    return np.array(beats), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train = extract_beats(train_records)\n",
        "X_test, y_test = extract_beats(test_records)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "\n",
        "import numpy as np\n",
        "print(\"Unique classes in train:\", np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        beat = self.X[idx].clone()\n",
        "\n",
        "        if self.augment:\n",
        "            # Gaussian noise\n",
        "            if random.random() > 0.5:\n",
        "                noise = torch.randn_like(beat) * 0.02\n",
        "                beat = beat + noise\n",
        "            \n",
        "            # Amplitude scaling\n",
        "            if random.random() > 0.5:\n",
        "                scale = random.uniform(0.9, 1.1)\n",
        "                beat = beat * scale\n",
        "            \n",
        "            # Time shifting (circular shift)\n",
        "            if random.random() > 0.5:\n",
        "                shift = random.randint(-10, 10)\n",
        "                beat = torch.roll(beat, shift, dims=-1)\n",
        "            \n",
        "            # Baseline wander\n",
        "            if random.random() > 0.5:\n",
        "                baseline = torch.sin(torch.linspace(0, 4*3.14159, beat.size(-1))) * 0.05\n",
        "                beat = beat + baseline.unsqueeze(0)\n",
        "\n",
        "        return beat, self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
        "test_dataset = ECGDataset(X_test, y_test, augment=False)\n",
        "\n",
        "# Smaller batch size for better generalization\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha[targets]\n",
        "            focal_loss = at * focal_loss\n",
        "\n",
        "        return focal_loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "alpha = torch.tensor(class_weights, dtype=torch.float32)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alpha = alpha.to(device)\n",
        "\n",
        "print(\"Class weights:\", alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.query = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.key = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.value = nn.Conv1d(channels, channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, length = x.size()\n",
        "        \n",
        "        q = self.query(x).view(batch, -1, length).permute(0, 2, 1)\n",
        "        k = self.key(x).view(batch, -1, length)\n",
        "        v = self.value(x).view(batch, -1, length)\n",
        "        \n",
        "        attention = torch.bmm(q, k)\n",
        "        attention = F.softmax(attention / math.sqrt(channels // 8), dim=-1)\n",
        "        \n",
        "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, channels, length)\n",
        "        \n",
        "        return self.gamma * out + x\n",
        "\n",
        "\n",
        "class ECGResNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = ResidualBlock(32, 64, dropout=0.2)\n",
        "        self.layer3 = ResidualBlock(64, 128, dropout=0.3)\n",
        "        self.layer4 = ResidualBlock(128, 256, dropout=0.3)\n",
        "        self.layer5 = ResidualBlock(256, 256, dropout=0.4)\n",
        "        \n",
        "        self.attention = SelfAttention(256)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.bn_fc = nn.BatchNorm1d(256)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        \n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        \n",
        "        self.fc3 = nn.Linear(128, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        \n",
        "        x = self.attention(x)\n",
        "        \n",
        "        # Concatenate avg and max pooling\n",
        "        avg_pool = self.global_pool(x).squeeze(-1)\n",
        "        max_pool = self.global_max_pool(x).squeeze(-1)\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
        "        \n",
        "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ECGResNet().to(device)\n",
        "\n",
        "# Use AdamW with weight decay for better regularization\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "# Cosine annealing with warmup\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1, weight=None):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.weight = weight\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        n_class = pred.size(1)\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, target.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - self.smoothing) + self.smoothing / n_class\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "        \n",
        "        if self.weight is not None:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1)\n",
        "            loss = (loss * self.weight[target]).mean()\n",
        "        else:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "        return loss\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing=0.1, weight=alpha)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step(epoch + total / len(train_loader.dataset))\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += targets.size(0)\n",
        "                val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        \n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Acc: {train_acc:.2f}% \"\n",
        "              f\"Val Acc: {val_acc:.2f}% \"\n",
        "              f\"Best Val: {best_val_acc:.2f}% \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        \n",
        "        # Early stopping\n",
        "        if patience_counter >= 15:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "    \n",
        "    print(f\"\\nBest Validation Accuracy: {best_val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train = extract_beats(train_records)\n",
        "X_test, y_test = extract_beats(test_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharath2004-tech/cardiac-disease-detection/blob/main/cardiac%20disease%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgI42isP1YUY",
        "outputId": "ddbabc0a-46ea-4563-c087-0ba8e11867d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.12/dist-packages (4.3.1)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.0.1)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.3)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb\n",
        "\n",
        "\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OquLi3pk1zrf",
        "outputId": "8ce6801e-0d97-4949-f3ad-e92688439250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating record list for: 100\n",
            "Generating record list for: 101\n",
            "Generating record list for: 102\n",
            "Generating record list for: 103\n",
            "Generating record list for: 104\n",
            "Generating record list for: 105\n",
            "Generating record list for: 106\n",
            "Generating record list for: 107\n",
            "Generating record list for: 108\n",
            "Generating record list for: 109\n",
            "Generating record list for: 111\n",
            "Generating record list for: 112\n",
            "Generating record list for: 113\n",
            "Generating record list for: 114\n",
            "Generating record list for: 115\n",
            "Generating record list for: 116\n",
            "Generating record list for: 117\n",
            "Generating record list for: 118\n",
            "Generating record list for: 119\n",
            "Generating record list for: 121\n",
            "Generating record list for: 122\n",
            "Generating record list for: 123\n",
            "Generating record list for: 124\n",
            "Generating record list for: 200\n",
            "Generating record list for: 201\n",
            "Generating record list for: 202\n",
            "Generating record list for: 203\n",
            "Generating record list for: 205\n",
            "Generating record list for: 207\n",
            "Generating record list for: 208\n",
            "Generating record list for: 209\n",
            "Generating record list for: 210\n",
            "Generating record list for: 212\n",
            "Generating record list for: 213\n",
            "Generating record list for: 214\n",
            "Generating record list for: 215\n",
            "Generating record list for: 217\n",
            "Generating record list for: 219\n",
            "Generating record list for: 220\n",
            "Generating record list for: 221\n",
            "Generating record list for: 222\n",
            "Generating record list for: 223\n",
            "Generating record list for: 228\n",
            "Generating record list for: 230\n",
            "Generating record list for: 231\n",
            "Generating record list for: 232\n",
            "Generating record list for: 233\n",
            "Generating record list for: 234\n",
            "Generating list of all files for: 100\n",
            "Generating list of all files for: 101\n",
            "Generating list of all files for: 102\n",
            "Generating list of all files for: 103\n",
            "Generating list of all files for: 104\n",
            "Generating list of all files for: 105\n",
            "Generating list of all files for: 106\n",
            "Generating list of all files for: 107\n",
            "Generating list of all files for: 108\n",
            "Generating list of all files for: 109\n",
            "Generating list of all files for: 111\n",
            "Generating list of all files for: 112\n",
            "Generating list of all files for: 113\n",
            "Generating list of all files for: 114\n",
            "Generating list of all files for: 115\n",
            "Generating list of all files for: 116\n",
            "Generating list of all files for: 117\n",
            "Generating list of all files for: 118\n",
            "Generating list of all files for: 119\n",
            "Generating list of all files for: 121\n",
            "Generating list of all files for: 122\n",
            "Generating list of all files for: 123\n",
            "Generating list of all files for: 124\n",
            "Generating list of all files for: 200\n",
            "Generating list of all files for: 201\n",
            "Generating list of all files for: 202\n",
            "Generating list of all files for: 203\n",
            "Generating list of all files for: 205\n",
            "Generating list of all files for: 207\n",
            "Generating list of all files for: 208\n",
            "Generating list of all files for: 209\n",
            "Generating list of all files for: 210\n",
            "Generating list of all files for: 212\n",
            "Generating list of all files for: 213\n",
            "Generating list of all files for: 214\n",
            "Generating list of all files for: 215\n",
            "Generating list of all files for: 217\n",
            "Generating list of all files for: 219\n",
            "Generating list of all files for: 220\n",
            "Generating list of all files for: 221\n",
            "Generating list of all files for: 222\n",
            "Generating list of all files for: 223\n",
            "Generating list of all files for: 228\n",
            "Generating list of all files for: 230\n",
            "Generating list of all files for: 231\n",
            "Generating list of all files for: 232\n",
            "Generating list of all files for: 233\n",
            "Generating list of all files for: 234\n",
            "Downloading files...\n",
            "Finished downloading files\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "wfdb.dl_database(\n",
        "    'mitdb',\n",
        "    dl_dir='mitdb',\n",
        "    keep_subdirs=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF1UAJQj2_ck",
        "outputId": "96ddc9be-f3c8-4625-bce0-c0beabdba130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Signal shape: (650000,)\n",
            "Total beats: 2274\n"
          ]
        }
      ],
      "source": [
        "import wfdb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "record = wfdb.rdrecord('mitdb/100')\n",
        "annotation = wfdb.rdann('mitdb/100', 'atr')\n",
        "\n",
        "signal = record.p_signal[:,0]   # use first channel\n",
        "r_peaks = annotation.sample\n",
        "labels = annotation.symbol\n",
        "\n",
        "print(\"Signal shape:\", signal.shape)\n",
        "print(\"Total beats:\", len(r_peaks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fwx-2oH3o-3",
        "outputId": "ca446490-c987-4a24-8165-762ae2aee5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beats shape: (2271, 180)\n"
          ]
        }
      ],
      "source": [
        "beats = []\n",
        "beat_labels = []\n",
        "\n",
        "for i in range(len(r_peaks)):\n",
        "    start = r_peaks[i] - 90\n",
        "    end = r_peaks[i] + 90\n",
        "\n",
        "    if start > 0 and end < len(signal):\n",
        "        beat = signal[start:end]\n",
        "        beats.append(beat)\n",
        "        beat_labels.append(labels[i])\n",
        "\n",
        "beats = np.array(beats)\n",
        "print(\"Beats shape:\", beats.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qeduxmu46WDb"
      },
      "outputs": [],
      "source": [
        "AAMI_map = {\n",
        "    'N':'N','L':'N','R':'N','e':'N','j':'N',\n",
        "    'A':'S','a':'S','J':'S','S':'S',\n",
        "    'V':'V','E':'V',\n",
        "    'F':'F'\n",
        "}\n",
        "\n",
        "class_to_int = {'N':0,'S':1,'V':2,'F':3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKFp5fIhXmMf",
        "outputId": "efe05e56-99b2-4b2a-d33c-2466a2d89cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train records: 22\n",
            "Test records: 22\n",
            "Overlap: set()\n"
          ]
        }
      ],
      "source": [
        "# Standard DS1 (Train) and DS2 (Test) split used in research\n",
        "\n",
        "train_records = [\n",
        "    '101','106','108','109','112','114','115','116',\n",
        "    '118','119','122','124','201','203','205','207',\n",
        "    '208','209','215','220','223','230'\n",
        "]\n",
        "\n",
        "test_records = [\n",
        "    '100','103','105','111','113','117','121','123',\n",
        "    '200','202','210','212','213','214','219','221',\n",
        "    '222','228','231','232','233','234'\n",
        "]\n",
        "\n",
        "print(\"Train records:\", len(train_records))\n",
        "print(\"Test records:\", len(test_records))\n",
        "\n",
        "# Safety check (no leakage)\n",
        "print(\"Overlap:\", set(train_records) & set(test_records))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6Qwb46w8QTp"
      },
      "outputs": [],
      "source": [
        "def extract_beats(record_list):\n",
        "    beats = []\n",
        "    labels = []\n",
        "\n",
        "    for rec in record_list:\n",
        "        print(f\"Processing record {rec}...\")\n",
        "\n",
        "        record = wfdb.rdrecord(f'mitdb/{rec}')\n",
        "        annotation = wfdb.rdann(f'mitdb/{rec}', 'atr')\n",
        "\n",
        "        signal = record.p_signal[:, 0]   # Use first channel\n",
        "        r_peaks = annotation.sample\n",
        "        symbols = annotation.symbol\n",
        "\n",
        "        for i in range(len(r_peaks)):\n",
        "            start = r_peaks[i] - 90\n",
        "            end = r_peaks[i] + 90\n",
        "\n",
        "            if start > 0 and end < len(signal):\n",
        "                label = symbols[i]\n",
        "\n",
        "                if label in AAMI_map:\n",
        "                    beat = signal[start:end]\n",
        "\n",
        "                    # Per-beat normalization\n",
        "                    mean = np.mean(beat)\n",
        "                    std = np.std(beat)\n",
        "                    beat = (beat - mean) / (std + 1e-8)\n",
        "\n",
        "                    beats.append(beat)\n",
        "                    labels.append(class_to_int[AAMI_map[label]])\n",
        "\n",
        "    return np.array(beats), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6sNKRDGX_Oh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC2nYV5eXV9-",
        "outputId": "343f4b7e-156b-4b7e-9246-7e124cdcffe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing record 101...\n",
            "Processing record 106...\n",
            "Processing record 108...\n",
            "Processing record 109...\n",
            "Processing record 112...\n",
            "Processing record 114...\n",
            "Processing record 115...\n",
            "Processing record 116...\n",
            "Processing record 118...\n",
            "Processing record 119...\n",
            "Processing record 122...\n",
            "Processing record 124...\n",
            "Processing record 201...\n",
            "Processing record 203...\n",
            "Processing record 205...\n",
            "Processing record 207...\n",
            "Processing record 208...\n",
            "Processing record 209...\n",
            "Processing record 215...\n",
            "Processing record 220...\n",
            "Processing record 223...\n",
            "Processing record 230...\n",
            "Processing record 100...\n",
            "Processing record 103...\n",
            "Processing record 105...\n",
            "Processing record 111...\n",
            "Processing record 113...\n",
            "Processing record 117...\n",
            "Processing record 121...\n",
            "Processing record 123...\n",
            "Processing record 200...\n",
            "Processing record 202...\n",
            "Processing record 210...\n",
            "Processing record 212...\n",
            "Processing record 213...\n",
            "Processing record 214...\n",
            "Processing record 219...\n",
            "Processing record 221...\n",
            "Processing record 222...\n",
            "Processing record 228...\n",
            "Processing record 231...\n",
            "Processing record 232...\n",
            "Processing record 233...\n",
            "Processing record 234...\n",
            "Train shape: (51002, 180)\n",
            "Test shape: (49691, 180)\n",
            "Unique classes in train: [0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = extract_beats(train_records)\n",
        "X_test, y_test = extract_beats(test_records)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "\n",
        "import numpy as np\n",
        "print(\"Unique classes in train:\", np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX3YYtQj8hYT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        beat = self.X[idx].clone()\n",
        "\n",
        "        if self.augment:\n",
        "            # Gaussian noise\n",
        "            if random.random() > 0.5:\n",
        "\n",
        "                noise = torch.randn_like(beat) * 0.02        return beat, self.y[idx]\n",
        "\n",
        "                beat = beat + noise\n",
        "\n",
        "                            beat = beat + baseline.unsqueeze(0)\n",
        "\n",
        "            # Amplitude scaling                baseline = torch.sin(torch.linspace(0, 4*3.14159, beat.size(-1))) * 0.05\n",
        "\n",
        "            if random.random() > 0.5:            if random.random() > 0.5:\n",
        "\n",
        "                scale = random.uniform(0.9, 1.1)            # Baseline wander\n",
        "\n",
        "                beat = beat * scale            \n",
        "\n",
        "                            beat = torch.roll(beat, shift, dims=-1)\n",
        "\n",
        "            # Time shifting (circular shift)                shift = random.randint(-10, 10)\n",
        "            if random.random() > 0.5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFY3RMBn8uRh"
      },
      "outputs": [],
      "source": [
        "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
        "test_dataset = ECGDataset(X_test, y_test, augment=False)\n",
        "\n",
        "# Smaller batch size for better generalization\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHHP7mP81mT",
        "outputId": "dbce0d6e-cbb4-4986-82b5-858f48515537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0: 45856\n",
            "Class 1: 944\n",
            "Class 2: 3788\n",
            "Class 3: 414\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKRkkR0Y8-aC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha[targets]\n",
        "            focal_loss = at * focal_loss\n",
        "\n",
        "        return focal_loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnetEuEx9KXK",
        "outputId": "430a6382-f082-4a15-bd8a-c6ac75abbf85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: tensor([ 0.2781, 13.5069,  3.3660, 30.7983], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "alpha = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "print(\"Class weights:\", alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9dbIy8D9kRQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.query = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.key = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.value = nn.Conv1d(channels, channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, length = x.size()\n",
        "        \n",
        "        q = self.query(x).view(batch, -1, length).permute(0, 2, 1)\n",
        "        k = self.key(x).view(batch, -1, length)\n",
        "        v = self.value(x).view(batch, -1, length)\n",
        "        \n",
        "        attention = torch.bmm(q, k)\n",
        "        attention = F.softmax(attention / math.sqrt(channels // 8), dim=-1)\n",
        "        \n",
        "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, channels, length)\n",
        "        \n",
        "        return self.gamma * out + x\n",
        "\n",
        "\n",
        "class ECGResNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.layer1 = nn.Sequential(        return x\n",
        "\n",
        "            nn.Conv1d(1, 32, kernel_size=7, padding=3),        x = self.fc2(x)\n",
        "\n",
        "            nn.BatchNorm1d(32),        x = self.dropout(x)\n",
        "\n",
        "            nn.ReLU(),        x = F.relu(self.fc1(x))\n",
        "\n",
        "            nn.MaxPool1d(2)        x = self.global_pool(x).squeeze(-1)\n",
        "\n",
        "        )\n",
        "\n",
        "        x = self.layer4(x)   # NEW\n",
        "\n",
        "        self.layer2 = ResidualBlock(32, 64, dropout=0.2)        x = self.layer3(x)\n",
        "\n",
        "        self.layer3 = ResidualBlock(64, 128, dropout=0.3)        x = self.layer2(x)\n",
        "\n",
        "        self.layer4 = ResidualBlock(128, 256)   # NEW deeper block        x = self.layer1(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        self.fc2 = nn.Linear(128, 4)\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 128)          # updated input size        self.dropout = nn.Dropout(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdJffgB29lzK",
        "outputId": "9bd598ae-4266-4858-baa7-ec967eb637b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ECGResNet().to(device)\n",
        "\n",
        "# Use AdamW with weight decay for better regularization\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "# Cosine annealing with warmup\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ4iikPc9qnv"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1, weight=None):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.weight = weight\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        n_class = pred.size(1)\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, target.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - self.smoothing) + self.smoothing / n_class\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "        \n",
        "        if self.weight is not None:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1)\n",
        "            loss = (loss * self.weight[target]).mean()\n",
        "        else:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "        return loss\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing=0.1, weight=alpha)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step(epoch + total / len(train_loader.dataset))\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"\\nBest Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "        # Validation    \n",
        "\n",
        "        model.eval()            break\n",
        "\n",
        "        val_correct = 0            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "\n",
        "        val_total = 0        if patience_counter >= 15:\n",
        "\n",
        "        val_loss = 0        # Early stopping\n",
        "\n",
        "        \n",
        "\n",
        "        with torch.no_grad():              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "            for inputs, targets in test_loader:              f\"Best Val: {best_val_acc:.2f}% \"\n",
        "\n",
        "                inputs, targets = inputs.to(device), targets.to(device)              f\"Val Acc: {val_acc:.2f}% \"\n",
        "\n",
        "                outputs = model(inputs)              f\"Train Acc: {train_acc:.2f}% \"\n",
        "\n",
        "                loss = criterion(outputs, targets)        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            patience_counter += 1\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)        else:\n",
        "\n",
        "                val_total += targets.size(0)            patience_counter = 0\n",
        "\n",
        "                val_correct += (predicted == targets).sum().item()            best_val_acc = val_acc\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total        # Track best model\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp0059bQ933q"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MULGfOJNVJ80",
        "outputId": "fed1f95d-bfcf-4ce0-80f0-9f2bca640869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing record 101...\n",
            "Processing record 106...\n",
            "Processing record 108...\n",
            "Processing record 109...\n",
            "Processing record 112...\n",
            "Processing record 114...\n",
            "Processing record 115...\n",
            "Processing record 116...\n",
            "Processing record 118...\n",
            "Processing record 119...\n",
            "Processing record 122...\n",
            "Processing record 124...\n",
            "Processing record 201...\n",
            "Processing record 203...\n",
            "Processing record 205...\n",
            "Processing record 207...\n",
            "Processing record 208...\n",
            "Processing record 209...\n",
            "Processing record 215...\n",
            "Processing record 220...\n",
            "Processing record 223...\n",
            "Processing record 230...\n",
            "Processing record 100...\n",
            "Processing record 103...\n",
            "Processing record 105...\n",
            "Processing record 111...\n",
            "Processing record 113...\n",
            "Processing record 117...\n",
            "Processing record 121...\n",
            "Processing record 123...\n",
            "Processing record 200...\n",
            "Processing record 202...\n",
            "Processing record 210...\n",
            "Processing record 212...\n",
            "Processing record 213...\n",
            "Processing record 214...\n",
            "Processing record 219...\n",
            "Processing record 221...\n",
            "Processing record 222...\n",
            "Processing record 228...\n",
            "Processing record 231...\n",
            "Processing record 232...\n",
            "Processing record 233...\n",
            "Processing record 234...\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = extract_beats(train_records)\n",
        "X_test, y_test = extract_beats(test_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp0yPnXEVTMT",
        "outputId": "db5e72b8-3382-4725-e7b5-8ff6bf1e9cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "5g7V0Z3E9tVs",
        "outputId": "191a18ea-102a-46ca-da9a-faa38f8d5afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/35] Train Acc: 76.55% Val Acc: 48.29%\n",
            "Epoch [2/35] Train Acc: 88.22% Val Acc: 65.10%\n",
            "Epoch [3/35] Train Acc: 91.06% Val Acc: 55.56%\n",
            "Epoch [4/35] Train Acc: 92.85% Val Acc: 70.31%\n",
            "Epoch [5/35] Train Acc: 93.50% Val Acc: 67.60%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3639108109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-49601024.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#  Gradient Clipping (NEW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             )\n\u001b[0;32m--> 630\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPaKo4msKBc5jQZLXlBRpfB",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
