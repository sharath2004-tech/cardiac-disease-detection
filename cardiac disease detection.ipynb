{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharath2004-tech/cardiac-disease-detection/blob/main/cardiac%20disease%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p2Jeth8dGHR",
        "outputId": "0836c48c-2269-4998-877e-5defed3f1d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-3.0.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.3)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n",
            "Downloading wfdb-4.3.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-3.0.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, wfdb\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 3.0.1 which is incompatible.\n",
            "dask-cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "gradio 5.50.0 requires pandas<3.0,>=1.0, but you have pandas 3.0.1 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "bqplot 0.12.45 requires pandas<3.0.0,>=1.0.0, but you have pandas 3.0.1 which is incompatible.\n",
            "db-dtypes 1.5.0 requires pandas<3.0.0,>=1.5.3, but you have pandas 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-3.0.1 wfdb-4.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb\n",
        "\n",
        "\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I73C5-hjdGHS",
        "outputId": "e1eb49c4-2fb4-4968-e353-011eac0df601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating record list for: 100\n",
            "Generating record list for: 101\n",
            "Generating record list for: 102\n",
            "Generating record list for: 103\n",
            "Generating record list for: 104\n",
            "Generating record list for: 105\n",
            "Generating record list for: 106\n",
            "Generating record list for: 107\n",
            "Generating record list for: 108\n",
            "Generating record list for: 109\n",
            "Generating record list for: 111\n",
            "Generating record list for: 112\n",
            "Generating record list for: 113\n",
            "Generating record list for: 114\n",
            "Generating record list for: 115\n",
            "Generating record list for: 116\n",
            "Generating record list for: 117\n",
            "Generating record list for: 118\n",
            "Generating record list for: 119\n",
            "Generating record list for: 121\n",
            "Generating record list for: 122\n",
            "Generating record list for: 123\n",
            "Generating record list for: 124\n",
            "Generating record list for: 200\n",
            "Generating record list for: 201\n",
            "Generating record list for: 202\n",
            "Generating record list for: 203\n",
            "Generating record list for: 205\n",
            "Generating record list for: 207\n",
            "Generating record list for: 208\n",
            "Generating record list for: 209\n",
            "Generating record list for: 210\n",
            "Generating record list for: 212\n",
            "Generating record list for: 213\n",
            "Generating record list for: 214\n",
            "Generating record list for: 215\n",
            "Generating record list for: 217\n",
            "Generating record list for: 219\n",
            "Generating record list for: 220\n",
            "Generating record list for: 221\n",
            "Generating record list for: 222\n",
            "Generating record list for: 223\n",
            "Generating record list for: 228\n",
            "Generating record list for: 230\n",
            "Generating record list for: 231\n",
            "Generating record list for: 232\n",
            "Generating record list for: 233\n",
            "Generating record list for: 234\n",
            "Generating list of all files for: 100\n",
            "Generating list of all files for: 101\n",
            "Generating list of all files for: 102\n",
            "Generating list of all files for: 103\n",
            "Generating list of all files for: 104\n",
            "Generating list of all files for: 105\n",
            "Generating list of all files for: 106\n",
            "Generating list of all files for: 107\n",
            "Generating list of all files for: 108\n",
            "Generating list of all files for: 109\n",
            "Generating list of all files for: 111\n",
            "Generating list of all files for: 112\n",
            "Generating list of all files for: 113\n",
            "Generating list of all files for: 114\n",
            "Generating list of all files for: 115\n",
            "Generating list of all files for: 116\n",
            "Generating list of all files for: 117\n",
            "Generating list of all files for: 118\n",
            "Generating list of all files for: 119\n",
            "Generating list of all files for: 121\n",
            "Generating list of all files for: 122\n",
            "Generating list of all files for: 123\n",
            "Generating list of all files for: 124\n",
            "Generating list of all files for: 200\n",
            "Generating list of all files for: 201\n",
            "Generating list of all files for: 202\n",
            "Generating list of all files for: 203\n",
            "Generating list of all files for: 205\n",
            "Generating list of all files for: 207\n",
            "Generating list of all files for: 208\n",
            "Generating list of all files for: 209\n",
            "Generating list of all files for: 210\n",
            "Generating list of all files for: 212\n",
            "Generating list of all files for: 213\n",
            "Generating list of all files for: 214\n",
            "Generating list of all files for: 215\n",
            "Generating list of all files for: 217\n",
            "Generating list of all files for: 219\n",
            "Generating list of all files for: 220\n",
            "Generating list of all files for: 221\n",
            "Generating list of all files for: 222\n",
            "Generating list of all files for: 223\n",
            "Generating list of all files for: 228\n",
            "Generating list of all files for: 230\n",
            "Generating list of all files for: 231\n",
            "Generating list of all files for: 232\n",
            "Generating list of all files for: 233\n",
            "Generating list of all files for: 234\n",
            "Created local base download directory: mitdb\n",
            "Downloading files...\n",
            "Finished downloading files\n"
          ]
        }
      ],
      "source": [
        "wfdb.dl_database(\n",
        "    'mitdb',\n",
        "    dl_dir='mitdb',\n",
        "    keep_subdirs=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_itPsjMdGHS",
        "outputId": "911543eb-67d8-4704-f450-0e2b47fa3741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Signal shape: (650000,)\n",
            "Total beats: 2274\n"
          ]
        }
      ],
      "source": [
        "import wfdb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "record = wfdb.rdrecord('mitdb/100')\n",
        "annotation = wfdb.rdann('mitdb/100', 'atr')\n",
        "\n",
        "signal = record.p_signal[:,0]   # use first channel\n",
        "r_peaks = annotation.sample\n",
        "labels = annotation.symbol\n",
        "\n",
        "print(\"Signal shape:\", signal.shape)\n",
        "print(\"Total beats:\", len(r_peaks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfJSmA0qdGHT",
        "outputId": "4bb2a85e-2b90-497d-a459-cbe3da72a321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beats shape: (2271, 180)\n"
          ]
        }
      ],
      "source": [
        "beats = []\n",
        "beat_labels = []\n",
        "\n",
        "for i in range(len(r_peaks)):\n",
        "    start = r_peaks[i] - 90\n",
        "    end = r_peaks[i] + 90\n",
        "\n",
        "    if start > 0 and end < len(signal):\n",
        "        beat = signal[start:end]\n",
        "        beats.append(beat)\n",
        "        beat_labels.append(labels[i])\n",
        "\n",
        "beats = np.array(beats)\n",
        "print(\"Beats shape:\", beats.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HwSiNcnrdGHT"
      },
      "outputs": [],
      "source": [
        "AAMI_map = {\n",
        "    'N':'N','L':'N','R':'N','e':'N','j':'N',\n",
        "    'A':'S','a':'S','J':'S','S':'S',\n",
        "    'V':'V','E':'V',\n",
        "    'F':'F'\n",
        "}\n",
        "\n",
        "class_to_int = {'N':0,'S':1,'V':2,'F':3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy0TPZhldGHU",
        "outputId": "f777f6e6-831e-44ff-b357-626abc83d8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train records: 22\n",
            "Test records: 22\n",
            "Overlap: set()\n"
          ]
        }
      ],
      "source": [
        "# Standard DS1 (Train) and DS2 (Test) split used in research\n",
        "\n",
        "train_records = [\n",
        "    '101','106','108','109','112','114','115','116',\n",
        "    '118','119','122','124','201','203','205','207',\n",
        "    '208','209','215','220','223','230'\n",
        "]\n",
        "\n",
        "test_records = [\n",
        "    '100','103','105','111','113','117','121','123',\n",
        "    '200','202','210','212','213','214','219','221',\n",
        "    '222','228','231','232','233','234'\n",
        "]\n",
        "\n",
        "print(\"Train records:\", len(train_records))\n",
        "print(\"Test records:\", len(test_records))\n",
        "\n",
        "# Safety check (no leakage)\n",
        "print(\"Overlap:\", set(train_records) & set(test_records))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V3CUjCATdGHU"
      },
      "outputs": [],
      "source": [
        "def extract_beats(record_list):\n",
        "    beats = []\n",
        "    labels = []\n",
        "\n",
        "    for rec in record_list:\n",
        "        print(f\"Processing record {rec}...\")\n",
        "\n",
        "        record = wfdb.rdrecord(f'mitdb/{rec}')\n",
        "        annotation = wfdb.rdann(f'mitdb/{rec}', 'atr')\n",
        "\n",
        "        signal = record.p_signal[:, 0]   # Use first channel\n",
        "        r_peaks = annotation.sample\n",
        "        symbols = annotation.symbol\n",
        "\n",
        "        for i in range(len(r_peaks)):\n",
        "            start = r_peaks[i] - 90\n",
        "            end = r_peaks[i] + 90\n",
        "\n",
        "            if start > 0 and end < len(signal):\n",
        "                label = symbols[i]\n",
        "\n",
        "                if label in AAMI_map:\n",
        "                    beat = signal[start:end]\n",
        "\n",
        "                    # Per-beat normalization\n",
        "                    mean = np.mean(beat)\n",
        "                    std = np.std(beat)\n",
        "                    beat = (beat - mean) / (std + 1e-8)\n",
        "\n",
        "                    beats.append(beat)\n",
        "                    labels.append(class_to_int[AAMI_map[label]])\n",
        "\n",
        "    return np.array(beats), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5erwntlRdGHV",
        "outputId": "4f346e47-da3d-4adf-e6c4-6c9eec0a7259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing record 101...\n",
            "Processing record 106...\n",
            "Processing record 108...\n",
            "Processing record 109...\n",
            "Processing record 112...\n",
            "Processing record 114...\n",
            "Processing record 115...\n",
            "Processing record 116...\n",
            "Processing record 118...\n",
            "Processing record 119...\n",
            "Processing record 122...\n",
            "Processing record 124...\n",
            "Processing record 201...\n",
            "Processing record 203...\n",
            "Processing record 205...\n",
            "Processing record 207...\n",
            "Processing record 208...\n",
            "Processing record 209...\n",
            "Processing record 215...\n",
            "Processing record 220...\n",
            "Processing record 223...\n",
            "Processing record 230...\n",
            "Processing record 100...\n",
            "Processing record 103...\n",
            "Processing record 105...\n",
            "Processing record 111...\n",
            "Processing record 113...\n",
            "Processing record 117...\n",
            "Processing record 121...\n",
            "Processing record 123...\n",
            "Processing record 200...\n",
            "Processing record 202...\n",
            "Processing record 210...\n",
            "Processing record 212...\n",
            "Processing record 213...\n",
            "Processing record 214...\n",
            "Processing record 219...\n",
            "Processing record 221...\n",
            "Processing record 222...\n",
            "Processing record 228...\n",
            "Processing record 231...\n",
            "Processing record 232...\n",
            "Processing record 233...\n",
            "Processing record 234...\n",
            "Train shape: (51002, 180)\n",
            "Test shape: (49691, 180)\n",
            "Unique classes in train: [0 1 2 3]\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = extract_beats(train_records)\n",
        "X_test, y_test = extract_beats(test_records)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "\n",
        "import numpy as np\n",
        "print(\"Unique classes in train:\", np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jS3lxlAqdGHV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        beat = self.X[idx].clone()\n",
        "\n",
        "        if self.augment:\n",
        "            # Gaussian noise\n",
        "            if random.random() > 0.5:\n",
        "                noise = torch.randn_like(beat) * 0.02\n",
        "                beat = beat + noise\n",
        "\n",
        "            # Amplitude scaling\n",
        "            if random.random() > 0.5:\n",
        "                scale = random.uniform(0.9, 1.1)\n",
        "                beat = beat * scale\n",
        "\n",
        "            # Time shifting (circular shift)\n",
        "            if random.random() > 0.5:\n",
        "                shift = random.randint(-10, 10)\n",
        "                beat = torch.roll(beat, shift, dims=-1)\n",
        "\n",
        "            # Baseline wander\n",
        "            if random.random() > 0.5:\n",
        "                baseline = torch.sin(torch.linspace(0, 4*3.14159, beat.size(-1))) * 0.05\n",
        "                beat = beat + baseline.unsqueeze(0)\n",
        "\n",
        "        return beat, self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h_HDFWk0dGHV"
      },
      "outputs": [],
      "source": [
        "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
        "test_dataset = ECGDataset(X_test, y_test, augment=False)\n",
        "\n",
        "# Smaller batch size for better generalization\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzljxzgEdGHW",
        "outputId": "d98b1a16-75ca-4649-b857-4f2b631f7c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0: 45856\n",
            "Class 1: 944\n",
            "Class 2: 3788\n",
            "Class 3: 414\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtSY8J4VdGHW",
        "outputId": "15ce62a3-026a-486e-bfeb-37f12ab1df7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: tensor([ 0.2781, 13.5069,  3.3660, 30.7983], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "alpha = torch.tensor(class_weights, dtype=torch.float32)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alpha = alpha.to(device)\n",
        "\n",
        "print(\"Class weights:\", alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bCmK-yrCdGHW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.query = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.key = nn.Conv1d(channels, channels // 8, 1)\n",
        "        self.value = nn.Conv1d(channels, channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, length = x.size()\n",
        "\n",
        "        q = self.query(x).view(batch, -1, length).permute(0, 2, 1)\n",
        "        k = self.key(x).view(batch, -1, length)\n",
        "        v = self.value(x).view(batch, -1, length)\n",
        "\n",
        "        attention = torch.bmm(q, k)\n",
        "        attention = F.softmax(attention / math.sqrt(channels // 8), dim=-1)\n",
        "\n",
        "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, channels, length)\n",
        "\n",
        "        return self.gamma * out + x\n",
        "\n",
        "\n",
        "class ECGResNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = ResidualBlock(32, 64, dropout=0.2)\n",
        "        self.layer3 = ResidualBlock(64, 128, dropout=0.3)\n",
        "        self.layer4 = ResidualBlock(128, 256, dropout=0.3)\n",
        "        self.layer5 = ResidualBlock(256, 256, dropout=0.4)\n",
        "\n",
        "        self.attention = SelfAttention(256)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.bn_fc = nn.BatchNorm1d(256)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "\n",
        "        self.fc3 = nn.Linear(128, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "\n",
        "        x = self.attention(x)\n",
        "\n",
        "        # Concatenate avg and max pooling\n",
        "        avg_pool = self.global_pool(x).squeeze(-1)\n",
        "        max_pool = self.global_max_pool(x).squeeze(-1)\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
        "\n",
        "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfBaNsxVdGHX",
        "outputId": "d94a4957-3868-476b-caf0-d135d1416ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Model parameters: 1596869\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ECGResNet().to(device)\n",
        "\n",
        "# Use AdamW with weight decay for better regularization\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "# Cosine annealing with warmup\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XtZR28AYdGHX"
      },
      "outputs": [],
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1, weight=None):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        n_class = pred.size(1)\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, target.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - self.smoothing) + self.smoothing / n_class\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        if self.weight is not None:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1)\n",
        "            loss = (loss * self.weight[target]).mean()\n",
        "        else:\n",
        "            loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "        return loss\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing=0.1, weight=alpha)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step(epoch + total / len(train_loader.dataset))\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += targets.size(0)\n",
        "                val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "\n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Acc: {train_acc:.2f}% \"\n",
        "              f\"Val Acc: {val_acc:.2f}% \"\n",
        "              f\"Best Val: {best_val_acc:.2f}% \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= 15:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nBest Validation Accuracy: {best_val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "U6OuUlzRdGHX",
        "outputId": "2c13dc18-5edb-4ad9-adb7-7f297fb78645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50] Train Acc: 77.45% Val Acc: 52.73% Best Val: 52.73% LR: 0.000976\n",
            "Epoch [2/50] Train Acc: 90.10% Val Acc: 77.20% Best Val: 77.20% LR: 0.000905\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2686/796181236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2686/2741438827.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             )\n\u001b[0;32m--> 630\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
